{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e0840804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+----------+--------+------------+\n",
      "|Product_id|Customer_id|Order_date|Location|Source_Order|\n",
      "+----------+-----------+----------+--------+------------+\n",
      "|         1|          A|2023-01-01|   India|      Swiggy|\n",
      "|         2|          A|2022-01-01|   India|      Swiggy|\n",
      "|         2|          A|2023-01-07|   India|      Swiggy|\n",
      "|         3|          A|2023-01-10|   India|  Restaurant|\n",
      "|         3|          A|2022-01-11|   India|      Swiggy|\n",
      "+----------+-----------+----------+--------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructField, StructType, DateType, IntegerType, StringType\n",
    "\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Sales Analysis\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Define the schema\n",
    "schema = StructType([\n",
    "    StructField(\"Product_id\", IntegerType(), True),\n",
    "    StructField(\"Customer_id\", StringType(), True),\n",
    "    StructField(\"Order_date\", DateType(), True),\n",
    "    StructField(\"Location\", StringType(), True),\n",
    "    StructField(\"Source_Order\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Read the CSV file with the defined schema\n",
    "df = spark.read.format('csv') \\\n",
    "    .schema(schema) \\\n",
    "    .load('data/sales.csv')\n",
    "\n",
    "# Show the first 5 rows of the DataFrame\n",
    "df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01dde551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+----------+--------+------------+----+-----+-------+\n",
      "|Product_id|Customer_id|Order_date|Location|Source_Order|Year|month|quarter|\n",
      "+----------+-----------+----------+--------+------------+----+-----+-------+\n",
      "|         1|          A|2023-01-01|   India|      Swiggy|2023|    1|      1|\n",
      "|         2|          A|2022-01-01|   India|      Swiggy|2022|    1|      1|\n",
      "|         2|          A|2023-01-07|   India|      Swiggy|2023|    1|      1|\n",
      "|         3|          A|2023-01-10|   India|  Restaurant|2023|    1|      1|\n",
      "+----------+-----------+----------+--------+------------+----+-----+-------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add \" year , Month , Quarter \" Columns\n",
    "\n",
    "from pyspark.sql.functions import year , month , quarter\n",
    "df_t1 = df.withColumn('Year' , year(df['Order_date']))\n",
    "df_t2 = df_t1.withColumn('month' , month(df['Order_date']))\n",
    "df_t3 = df_t2.withColumn('quarter' , quarter(df['Order_date']))\n",
    "\n",
    "df_t3.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f81725b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+-----+\n",
      "|Product_id|Product_Name|Price|\n",
      "+----------+------------+-----+\n",
      "|         1|       PIZZA|  100|\n",
      "|         2|     Chowmin|  150|\n",
      "|         3|    sandwich|  120|\n",
      "|         4|        Dosa|  110|\n",
      "|         5|     Biryani|   80|\n",
      "+----------+------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importing Menu Data\n",
    "\n",
    "schema = StructType([\n",
    "  StructField(\"Product_id\" , IntegerType() , True),\n",
    "  StructField(\"Product_Name\" , StringType() , True),\n",
    "  StructField(\"Price\" , StringType() , True),\n",
    "\n",
    "  ])\n",
    "\n",
    "Menu = spark.read.format('csv') \\\n",
    "  .schema(schema) \\\n",
    "  .load('data/menu.csv.')\n",
    "\n",
    "Menu.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63b8ae68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+----------+--------+------------+----+-----+-------+------------+-----+\n",
      "|Product_id|Customer_id|Order_date|Location|Source_Order|Year|month|quarter|Product_Name|Price|\n",
      "+----------+-----------+----------+--------+------------+----+-----+-------+------------+-----+\n",
      "|         1|          A|2023-01-01|   India|      Swiggy|2023|    1|      1|       PIZZA|  100|\n",
      "|         2|          A|2022-01-01|   India|      Swiggy|2022|    1|      1|     Chowmin|  150|\n",
      "|         2|          A|2023-01-07|   India|      Swiggy|2023|    1|      1|     Chowmin|  150|\n",
      "|         3|          A|2023-01-10|   India|  Restaurant|2023|    1|      1|    sandwich|  120|\n",
      "+----------+-----------+----------+--------+------------+----+-----+-------+------------+-----+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Merge Sales & Menu\n",
    "\n",
    "Sales = df_t3\n",
    "merge = Sales.join(Menu , 'Product_id' , 'inner')\n",
    "merge.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4d419502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+\n",
      "|Customer_id| total|\n",
      "+-----------+------+\n",
      "|          B|4440.0|\n",
      "|          A|4260.0|\n",
      "|          C|2400.0|\n",
      "|          E|2040.0|\n",
      "|          D|1200.0|\n",
      "+-----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Total amount Spent by Customer\n",
    "\n",
    "from pyspark.sql.functions import sum, desc\n",
    "\n",
    "total_amt_Customer = merge.groupBy('Customer_id').agg(sum('Price').alias('total')).orderBy(desc('total'))\n",
    "total_amt_Customer.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "51e56600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+\n",
      "|Product_Name| Total|\n",
      "+------------+------+\n",
      "|    sandwich|5760.0|\n",
      "|     Chowmin|3600.0|\n",
      "|       PIZZA|2100.0|\n",
      "|        Dosa|1320.0|\n",
      "|       Pasta|1080.0|\n",
      "|     Biryani| 480.0|\n",
      "+------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Total amount Spent by each food Category\n",
    "total_amt_food = merge.groupBy('Product_Name').agg(sum('Price').alias('Total')).orderBy(desc('Total'))\n",
    "total_amt_food.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "185b1094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|month| Total|\n",
      "+-----+------+\n",
      "|    1|2960.0|\n",
      "|    2|2730.0|\n",
      "|    3| 910.0|\n",
      "|    5|2960.0|\n",
      "|    6|2960.0|\n",
      "|    7| 910.0|\n",
      "|   11| 910.0|\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Total amount of Sales in each Month\n",
    "\n",
    "total_amt_Month = merge.groupBy('month').agg(sum('Price').alias('Total')).orderBy('month')\n",
    "total_amt_Month.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ae2c7f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+\n",
      "|Year| Total|\n",
      "+----+------+\n",
      "|2022|4350.0|\n",
      "|2023|9990.0|\n",
      "+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Yearly Sales\n",
    "\n",
    "total_amt_Year = merge.groupBy('Year').agg(sum('Price').alias('Total')).orderBy('Year')\n",
    "total_amt_Year.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c9e87e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|quarter| Total|\n",
      "+-------+------+\n",
      "|      1|6600.0|\n",
      "|      2|5920.0|\n",
      "|      3| 910.0|\n",
      "|      4| 910.0|\n",
      "+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# quarter Sales\n",
    "\n",
    "total_amt_quarter = merge.groupBy('quarter').agg(sum('Price').alias('Total')).orderBy('quarter')\n",
    "total_amt_quarter.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ac6395e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+\n",
      "|Product_Name|cnt_orders|\n",
      "+------------+----------+\n",
      "|    sandwich|        48|\n",
      "|     Chowmin|        24|\n",
      "|       PIZZA|        21|\n",
      "|        Dosa|        12|\n",
      "|       Pasta|         6|\n",
      "|     Biryani|         6|\n",
      "+------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# How many times each product purchased ? \n",
    "\n",
    "product_purchased = merge.groupBy('Product_Name').agg(count('*').alias('cnt_orders')).orderBy(desc('cnt_orders'))\n",
    "product_purchased.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "eab8c8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---+\n",
      "|Customer_id|cnt|\n",
      "+-----------+---+\n",
      "|          B|  6|\n",
      "|          A|  6|\n",
      "|          E|  5|\n",
      "|          C|  3|\n",
      "|          D|  1|\n",
      "+-----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Frequency of Customer visiting Restaurant\n",
    "\n",
    "Customer_purchase1 = merge.filter(merge.Source_Order == 'Restaurant').groupBy('Customer_id').agg(countDistinct('Order_date').alias('cnt')).orderBy(desc('cnt'))\n",
    "Customer_purchase1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6f85e656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n",
      "|Location| Total|\n",
      "+--------+------+\n",
      "|      UK|7020.0|\n",
      "|   India|4860.0|\n",
      "|     USA|2460.0|\n",
      "+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Total Sales By each Country\n",
    "\n",
    "Country_sales = merge.groupBy('Location').agg(sum('Price').alias('Total')).orderBy(desc('Total'))\n",
    "Country_sales.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "556972c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+\n",
      "|Source_Order| Total|\n",
      "+------------+------+\n",
      "|      Swiggy|6330.0|\n",
      "|      zomato|4920.0|\n",
      "|  Restaurant|3090.0|\n",
      "+------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Total sales by Order Source\n",
    "\n",
    "source_order_sales = merge.groupBy('Source_Order').agg(sum('Price').alias('Total')).orderBy(desc('Total'))\n",
    "source_order_sales.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c778b1b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+\n",
      "|Customer_id|Total_Spend|\n",
      "+-----------+-----------+\n",
      "|          B|     4440.0|\n",
      "|          A|     4260.0|\n",
      "|          C|     2400.0|\n",
      "|          E|     2040.0|\n",
      "|          D|     1200.0|\n",
      "+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Top 5 Customers by Total Spend\n",
    "top_customers = merge.groupBy('Customer_id').agg(sum('Price').alias('Total_Spend')).orderBy(desc('Total_Spend')).limit(5)\n",
    "top_customers.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b489a89e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+\n",
      "|Customer_id|Avg_Spend|\n",
      "+-----------+---------+\n",
      "|          C|   133.33|\n",
      "|          A|   129.09|\n",
      "|          B|   123.33|\n",
      "|          E|   113.33|\n",
      "|          D|   100.00|\n",
      "+-----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Average Spend per Order by Customer\n",
    "from pyspark.sql.functions import avg, format_number\n",
    "\n",
    "avg_spend_per_order = merge.groupBy('Customer_id') \\\n",
    "    .agg(format_number(avg('Price'), 2).alias('Avg_Spend')) \\\n",
    "    .orderBy(desc('Avg_Spend'))\n",
    "\n",
    "avg_spend_per_order.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7dda9ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+-----------+\n",
      "|Product_Name|month|Order_Count|\n",
      "+------------+-----+-----------+\n",
      "|    sandwich|    1|         10|\n",
      "|     Chowmin|    1|          6|\n",
      "|       PIZZA|    1|          5|\n",
      "|       Pasta|    1|          2|\n",
      "|    sandwich|    2|          9|\n",
      "|        Dosa|    2|          6|\n",
      "|       PIZZA|    2|          3|\n",
      "|     Chowmin|    2|          3|\n",
      "|     Biryani|    2|          3|\n",
      "|    sandwich|    3|          3|\n",
      "|        Dosa|    3|          2|\n",
      "|     Chowmin|    3|          1|\n",
      "|     Biryani|    3|          1|\n",
      "|       PIZZA|    3|          1|\n",
      "|    sandwich|    5|         10|\n",
      "|     Chowmin|    5|          6|\n",
      "|       PIZZA|    5|          5|\n",
      "|       Pasta|    5|          2|\n",
      "|    sandwich|    6|         10|\n",
      "|     Chowmin|    6|          6|\n",
      "+------------+-----+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Product Popularity by Month\n",
    "product_popularity_month = merge.groupBy('Product_Name', 'month').agg(count('*').alias('Order_Count')).orderBy('month', desc('Order_Count'))\n",
    "product_popularity_month.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d6d3203d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+\n",
      "|Order_Date|Total_Sales|\n",
      "+----------+-----------+\n",
      "|2022-01-01|      300.0|\n",
      "|2022-01-07|      180.0|\n",
      "|2022-01-11|      240.0|\n",
      "|2022-02-01|      350.0|\n",
      "|2022-02-05|      350.0|\n",
      "|2022-02-06|      350.0|\n",
      "|2022-03-01|      260.0|\n",
      "|2022-03-16|      120.0|\n",
      "|2022-05-05|      300.0|\n",
      "|2022-05-07|      180.0|\n",
      "|2022-05-11|      240.0|\n",
      "|2022-06-06|      300.0|\n",
      "|2022-06-11|      420.0|\n",
      "|2022-07-05|      260.0|\n",
      "|2022-07-16|      120.0|\n",
      "|2022-11-06|      260.0|\n",
      "|2022-11-16|      120.0|\n",
      "|2023-01-01|      540.0|\n",
      "|2023-01-02|      300.0|\n",
      "|2023-01-04|      200.0|\n",
      "+----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sales Trend Over Time (Daily Sales)\n",
    "from pyspark.sql.functions import to_date\n",
    "daily_sales = merge.withColumn('Order_Date', to_date('Order_date')).groupBy('Order_Date').agg(sum('Price').alias('Total_Sales')).orderBy('Order_Date')\n",
    "daily_sales.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d5dc987b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------------------+\n",
      "|Product_Name|Contribution_Percentage|\n",
      "+------------+-----------------------+\n",
      "|        Dosa|                   9.21|\n",
      "|       Pasta|                   7.53|\n",
      "|    sandwich|                  40.17|\n",
      "|     Biryani|                   3.35|\n",
      "|     Chowmin|                  25.10|\n",
      "|       PIZZA|                  14.64|\n",
      "+------------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Percentage Contribution by Each Food Category\n",
    "from pyspark.sql.functions import sum, desc, format_number\n",
    "\n",
    "# Calculate the total sales\n",
    "total_sales = merge.agg(sum('Price').alias('Total_Sales')).collect()[0]['Total_Sales']\n",
    "\n",
    "# Calculate the contribution percentage for each food category\n",
    "contribution = merge.groupBy('Product_Name') \\\n",
    "    .agg(format_number((sum('Price')/total_sales*100), 2).alias('Contribution_Percentage')) \\\n",
    "    .orderBy(desc('Contribution_Percentage'))\n",
    "\n",
    "contribution.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "add122a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+\n",
      "|Source_Order|Total_Sales|\n",
      "+------------+-----------+\n",
      "|      Swiggy|     6330.0|\n",
      "|      zomato|     4920.0|\n",
      "|  Restaurant|     3090.0|\n",
      "+------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sales Comparison Between Different Order Sources\n",
    "source_comparison = merge.groupBy('Source_Order').agg(sum('Price').alias('Total_Sales')).orderBy(desc('Total_Sales'))\n",
    "source_comparison.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c5e6c394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+--------------+------------------+\n",
      "|month|Total_Sales|Previous_Sales|       Growth_Rate|\n",
      "+-----+-----------+--------------+------------------+\n",
      "|    1|     2960.0|          NULL|              NULL|\n",
      "|    2|     2730.0|        2960.0| -7.77027027027027|\n",
      "|    3|      910.0|        2730.0|-66.66666666666666|\n",
      "|    5|     2960.0|         910.0|225.27472527472528|\n",
      "|    6|     2960.0|        2960.0|               0.0|\n",
      "|    7|      910.0|        2960.0|-69.25675675675676|\n",
      "|   11|      910.0|         910.0|               0.0|\n",
      "+-----+-----------+--------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Month-wise Sales Growth Rate\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import lag\n",
    "\n",
    "windowSpec = Window.orderBy(\"month\")\n",
    "monthly_sales = merge.groupBy('month').agg(sum('Price').alias('Total_Sales')).orderBy('month')\n",
    "monthly_sales = monthly_sales.withColumn(\"Previous_Sales\", lag(monthly_sales['Total_Sales']).over(windowSpec))\n",
    "monthly_sales = monthly_sales.withColumn(\"Growth_Rate\", ((monthly_sales['Total_Sales'] - monthly_sales['Previous_Sales']) / monthly_sales['Previous_Sales']) * 100)\n",
    "monthly_sales.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fcd5153d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+---------------+\n",
      "|Customer_id|Year|Orders_Per_Year|\n",
      "+-----------+----+---------------+\n",
      "|          A|2022|              6|\n",
      "|          A|2023|             11|\n",
      "|          B|2022|              6|\n",
      "|          B|2023|             16|\n",
      "|          C|2022|              3|\n",
      "|          C|2023|              6|\n",
      "|          D|2022|              6|\n",
      "|          D|2023|              4|\n",
      "|          E|2022|              3|\n",
      "|          E|2023|             11|\n",
      "+-----------+----+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Customer Retention Analysis\n",
    "retention = merge.groupBy('Customer_id', 'Year').agg(countDistinct('Order_date').alias('Orders_Per_Year')).orderBy('Customer_id', 'Year')\n",
    "retention.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "07aa8a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+\n",
      "|Product_Name|Total_Sales|\n",
      "+------------+-----------+\n",
      "|    sandwich|   5,760.00|\n",
      "|     Biryani|     480.00|\n",
      "|     Chowmin|   3,600.00|\n",
      "|       PIZZA|   2,100.00|\n",
      "|        Dosa|   1,320.00|\n",
      "|       Pasta|   1,080.00|\n",
      "+------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate the total sales amount for each product.\n",
    "\n",
    "total_sales_by_product = merge.groupBy('Product_Name') \\\n",
    "    .agg(format_number(sum('Price'), 2).alias('Total_Sales')) \\\n",
    "    .orderBy(desc('Total_Sales'))\n",
    "\n",
    "total_sales_by_product.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "258b8832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------------------+\n",
      "|Location|Contribution_Percentage|\n",
      "+--------+-----------------------+\n",
      "|      UK|                  48.95|\n",
      "|   India|                  33.89|\n",
      "|     USA|                  17.15|\n",
      "+--------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##  Percentage Contribution by Location\n",
    "# Calculate the percentage contribution of each location to the total sales.\n",
    "\n",
    "# Calculate the total sales\n",
    "total_sales = merge.agg(sum('Price').alias('Total_Sales')).collect()[0]['Total_Sales']\n",
    "\n",
    "# Calculate the contribution percentage by location\n",
    "contribution_by_location = merge.groupBy('Location') \\\n",
    "    .agg(format_number((sum('Price') / total_sales * 100), 2).alias('Contribution_Percentage')) \\\n",
    "    .orderBy(desc('Contribution_Percentage'))\n",
    "\n",
    "contribution_by_location.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cf3cb1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+---------+\n",
      "|Customer_id|month|Avg_Spend|\n",
      "+-----------+-----+---------+\n",
      "|          A|    1|   129.09|\n",
      "|          A|    5|   129.09|\n",
      "|          A|    6|   129.09|\n",
      "|          B|    1|   123.33|\n",
      "|          B|    2|   123.33|\n",
      "|          B|    3|   123.33|\n",
      "|          B|    5|   123.33|\n",
      "|          B|    6|   123.33|\n",
      "|          B|    7|   123.33|\n",
      "|          B|   11|   123.33|\n",
      "|          C|    1|   133.33|\n",
      "|          C|    5|   133.33|\n",
      "|          C|    6|   133.33|\n",
      "|          D|    2|   100.00|\n",
      "|          D|    3|   100.00|\n",
      "|          D|    7|   100.00|\n",
      "|          D|   11|   100.00|\n",
      "|          E|    2|   113.33|\n",
      "|          E|    3|   113.33|\n",
      "|          E|    7|   113.33|\n",
      "+-----------+-----+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average spend per customer for each month\n",
    "from pyspark.sql.functions import avg\n",
    "\n",
    "monthly_avg_spend = merge.groupBy('Customer_id', 'month') \\\n",
    "    .agg(format_number(avg('Price'), 2).alias('Avg_Spend')) \\\n",
    "    .orderBy('Customer_id', 'month')\n",
    "\n",
    "monthly_avg_spend.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b6b21a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+---------+\n",
      "|Source_Order|Total_Sales|Avg_Price|\n",
      "+------------+-----------+---------+\n",
      "|      Swiggy|   6,330.00|   124.12|\n",
      "|      zomato|   4,920.00|   126.15|\n",
      "|  Restaurant|   3,090.00|   114.44|\n",
      "+------------+-----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Calculate the total sales and average price by order source.\n",
    "from pyspark.sql.functions import avg\n",
    "\n",
    "sales_by_source = merge.groupBy('Source_Order') \\\n",
    "    .agg(\n",
    "        format_number(sum('Price'), 2).alias('Total_Sales'),\n",
    "        format_number(avg('Price'), 2).alias('Avg_Price')\n",
    "    ) \\\n",
    "    .orderBy(desc('Total_Sales'))\n",
    "\n",
    "sales_by_source.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "20f9e187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------+\n",
      "|Product_Name|Avg_Price|\n",
      "+------------+---------+\n",
      "|     Biryani|    80.00|\n",
      "|       Pasta|   180.00|\n",
      "|     Chowmin|   150.00|\n",
      "|    sandwich|   120.00|\n",
      "|        Dosa|   110.00|\n",
      "+------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Find the top 5 most expensive products based on their average price.\n",
    "\n",
    "top_expensive_products = merge.groupBy('Product_Name') \\\n",
    "    .agg(format_number(avg('Price'), 2).alias('Avg_Price')) \\\n",
    "    .orderBy(desc('Avg_Price')) \\\n",
    "    .limit(5)\n",
    "\n",
    "top_expensive_products.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934c2f71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pyspark_env)",
   "language": "python",
   "name": "pyspark_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
